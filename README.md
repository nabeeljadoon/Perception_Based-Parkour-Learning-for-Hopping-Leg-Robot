# Perception Based Parkour Learning for Hopping Leg Robot
![image](https://github.com/user-attachments/assets/ea26dd5c-fed2-4c5f-bb65-1ba43d586073)
## **Research Overview**
This research explores the integration of **real-time perception** into **parkour navigation** for underactuated **legged robots**. The goal is to enhance robustness and adaptability in navigating **complex terrains** by incorporating **point cloud-based object detection** into motion planning and execution.

## **Key Contributions**
- **Mixed-Integer Programming (MIP) Path Planning**  
  - Efficiently computes feasible trajectories through known obstacles.  
- **Real-Time Object Detection via Point Cloud Perception**  
  - Enables **adaptive path planning** based on dynamic environments.  
- **PD Controller with Feedforward Torque Compensation**  
  - Executes planned motions in real-time for stable locomotion.  
- **Experimental Validation on "Hopping Leg on a Boomstick"**  
  - Successfully navigates diverse parkour scenarios.  

## **Technical Approach**
1. **Path Planning**  
   - MIP-based trajectory optimization for efficient movement.  
2. **Real-Time Perception**  
   - Point cloud processing to detect obstacles dynamically.  
3. **Motion Execution**  
   - PD controller with feedforward torques for stability.  
4. **Validation & Testing**  
   - Performance evaluated in structured parkour environments.  

## **Results & Impact**
- Successfully integrates **vision-guided control** into legged robot navigation.  
- Demonstrates **robust and efficient locomotion** in challenging environments.  
- Highlights the potential of **real-time perception** for enhanced robotic autonomy.  

## **Repository & Resources**
Link to the website: https://dfki-ric-underactuated-lab.github.io/summer_of_underactuation_2024/
Link to my Project Video: https://dfki-ric-underactuated-lab.github.io/summer_of_underactuation_2024/static/videos/Nabeel2.mp4

Thanks to @Dennis Mronga @Shubham Viyas for their Supervision.

